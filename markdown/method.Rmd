# Method
<!-- TODO: Add bias spec into methods -->
<!-- Notes: -->
<!-- conduct sensitivity anaylsis later? -->
<!-- Lakens 2020, sample size justification read! -->
<!-- Add the "later studies" when comparing results of sensitivity analysis -->
<!-- proportion of Nogo trials? -->

<!-- omega squared better effect size,  -->
<!-- bonferroni correction rausnehmen: Schulz, Grimes 2005 -->
<!-- Subjects in text == Participants -->

<!-- Distance to monitor  -->
<!-- Warum individuell keine ausreißer rausnehmen? Response window! -->
<!-- Abkürzungen 1x pro abschnitt? -->
<!-- Kurz was zur Verteilung der Normalverteilungen der RT sagen -->
```{r method-source-data-prep, child = "./markdown/data_prep.rmd"}
```

## Participants
```{r method-source-power-analysis, child = "./markdown/power_analysis.rmd", eval = TRUE}
```

```{r method-power-commented-out, eval = FALSE}
# <-- We conducted a power analysis using the the R package `superpower` [@R-Superpower] with values based on previous studies [@dutilh2012testing; @dutilh2013] to determine the minimum sample size needed to detect an interaction effect of RSI (short -- long) and _previous accuracy_ (post-correct -- post-error) on drift rate and boundary separation. Mean values and standard deviations for each cell were entered into the model to estimate effect sizes, returning interaction effects of partial $\eta^2 =$ `r partial_eta_interaction_drift` and `r partial_eta_interaction_boundary` for effects on drift rate and boundary separation, respectively. Using bonferroni corrected significance criteria of $\alpha$ = `r alpha_level_power` and power $= .80$, the minimum sample size required to detect the hypothesized interaction effects was estimated to be N = `r required_n_boundary` for effects on boundary separation and N = `r required_n_drift` for effects on drift rate. Exact values entered into analysis can be found in Table \@ref(tab:appendix-mean-values-power-analysis) in the appendix. -->
```
We recruited a total of `r demo_output$n_subjects` (`r demo_output$n_women` females, M = `r round(demo_output$mean_age, 2)`, SD = `r round(demo_output$sd_age, 2)`) participants. Participants were tested in a single session, gave informed consent and received course credit for their participation.

## Materials
The experiment was programmed using the PsychoPy software [@peirce2019]. We used a modified version of the Behavior Adaptation Task (BAT) [@hester2007] -- a motor-inhibition Go-NoGo task. Stimuli consisted of a stream of the letters X and Y presented in black centrally on a grey background (see Figure \@ref(fig:method-bat-example)). Participants were asked to respond to the letters when they occurred in an alternating pattern (Go trial) but withhold their response on repeated presentation of a stimulus (NoGo trial). Letters measured approximately 2.5 degrees vertically, the fixation cross measured 1 degree horizontally and vertically and was printed black. Participants were seated approximately 60cm away from the monitor.

(ref:method-bat-example-caption) Behavioral Adaptation Task

```{r method-bat-example, fig.cap = paste("(ref:method-bat-example-caption)")}
knitr::include_graphics(
  "images/bat_slide_pp/Slide1.png"
)
```

<!-- ![Behavior Adaptation Task](images/bat_slide_pp/Slide1.png) -->


## Procedure
Participants were asked to respond as quickly and accurately as possible. Instructions on response mappings of stimuli X and Y to the response keys D and L were counterbalanced across participants. Stimuli were presented for 800ms or until a response was given. We set the RSI to 200ms for the short condition and 1000ms for the long condition. A fixation cross was presented during the RSI. Participants completed 30 practice trials, 15 of which with short RSI and 15 with long RSI. Participants received feedback informing them about their performance only in practice trials. The word "richtig" (german for _correct_) was printed in green following a correct response, "falsch" (german for _incorrect_) was printed in red following a false response. When participants erroneously responded in a NoGo-trial, they were reminded not to respond when stimuli were repeated. RSI was manipulated between experimental blocks, with six blocks consisting of 250 trials each being presented per RSI condition. Blocks of short and long RSI occurred in an alternating pattern, beginning with the long RSI condition. A self-paced break was administered following each experimental block. **instruction screens (german) can be found in supplementary materials?)** The sequence of appearance of stimuli X and Y was generated pseudo-randomly. Fourfold repetitions of a stimulus were prohibited, and NoGo-trials were always preceded by another NoGo trial or at least two Go trials. This was done to ensure that post-error trials were never simultaneously pre-error trials. 

## Data preparation
All response times shorter than 150ms were excluded from analysis. Mean RT and accuracy for each participant in each combination of RSI (short -- long) and trial type (Go -- NoGo) were considered outliers if the participant's mean deviated more than 3 standard deviations from the mean across participants for that combination of RSI and trial type. A total of `r n_outliers` participants were excluded due to this criterion, leaving `r demo_output$n_subjects - n_outliers` participants for analysis. Since response times had an upper limit of 800ms, we chose not to exclude trials on a within-participant basis.

<!-- Exclude first 10 trials in each first occurence of RSI block -->
<!-- Within-participant logarithmized response times deviating more than 3 standard deviations from the participants' condition-specific mean were also considered outliers. Of the `r nrow(rt_data)` trials `r paste(formattable::percent((n_outliers*3000) / nrow(final_data)))` of trials were lost due to participant exclusion, `r demo_output$percentage_trials_lost`% of trials were lost due to single trial outliers, leaving `r nrow(final_data)` trials for analysis. -->

## Behavioral Analysis
Because very few errors of commission occurred in Go trials, only errors in NoGo trials were considered _error trials_ relevant for analysis. Inspection of only the effect of accuracy in NoGo trials allows classification of Go trials based on the accuracy of the most proximate NoGo trial. Go trials following a NoGo-error are defined as trials _E+1_, Go trials following a correct response to a NoGo-trial as _C+1_. We also added the locations _E-1_, _C-1_, _E+2_, _C+2_, _E+3_, _C+3_, _E+4_ and _C+4_ depending on the distance to and accuracy of the most proximate NoGo trial^[A more in-depth definition of the criteria used in trial specification is provided in the appendix **NUMBER**]. We will use this _full location_ dataset when fitting the DDM to gain a better understanding of the changes in model parameters following error responses. The factor _location_ will refer to this set of definitions of Go trials depending on the accuracy of and distance to the most proximate NoGo trial.

To quantify the impact of an error, this location-approach allows for the classification of post-error effects as done by traditional methods,
$$\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$$ 
as well as the robust approach to PES [@dutilh2012how].
$$ \Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{E-1}}$$

When investigating the specific impact of an error-response on the following trial we will conduct our analyses using the robust definition of PES to account for global shifts in performance^[We conducted all behavioral and DDM analysis with the classical measure of PES as well [@dutilh2012how]. Results did not differ significantly, see Appendix //REPLACE// for  details on global performance shifts and model results]. Parameters and behavioral measures in trials following an error will be compared to trials preceding an error to ensure that post-error trials and trials used to estimate a baseline originate from the same place in the dataset. This prevents biased sampling of post-error trials depending on global performance shifts. The factor _error-condition_ (pre-error -- post-error) will be used when quantifying post-error effects specifically.

<!-- Data belonging to the locations _E-1_, _E+1_, _C-1_ and _C+1_ can be categorized into a 2x2 factorial design with the factor _NoGo-accuracy_ describing the accuracy of the NoGo trial, regardless whether the Go-trial occured before or after the NoGo trial and the factor _distance_ describing wether a trial occured before or after a NoGo trial, regardless of the accuracy of that NoGo trial. The traditional account of PES is captured by the main effect of _NoGo-accuracy_ given that the _distance_ is 1 (after a NoGo trial). The robust account is the main effect of _distance_ given that the _NoGo-accuracy_ is 0 (an error). -->
<!-- Investigating the effect of one parameter while restricting the other however grants only partial insight into the effect of an error on trials following it. If there are differences in responses prior to a NoGo trial depending on the accuracy of the following NoGo trial, these effects are not post-error related and should be accounted for. -->

<!-- We will therefore consider the interaction between the two factors _NoGo-accuracy_ and _distance_ as evidence for post-error changes to information processing. When the effect of NoGo-accuracy is dependent on the distance to the NoGo trial and responses close to an error deviate more significantly from responses close to a correct response _after_ the NoGo trial, this difference is solely attributable to post-error effects. -->

<!-- Effects of the factors _RSI_, _NoGo-accuracy_ and _distance_ as well as their interaction on mean response times and accuracy are examined using a three-way ($RSI \times NoGo-accuracy \times distance$) repeated measures ANOVA. ^[All analysis will also be conducted using the traditional and robust approaches to post-error slowing. Results will be reported whenever they differ from our new approach. A full overview of analyses conducted using the other approaches can be found in the appendix.] -->

<!-- Herein lies the problem with using the traditional or robust approach in our experimental design. By restricting one factor and estimating the effects of the other, differences are not solely attributable to an error. In the traditional approach, differences between _C+1_ and _E+1_ might be due to global parameter differences near correct NoGo trials versus near incorrect NoGo trials. Phases in which participants respond less accurately increase the odds of an inaccurate response to a NoGo trial -->
<!-- - traditional doesnt account for differences between -1 and 1 distance -> if differences between correct go trials and error go trials are present even before the error occurs, (WHY would they, explain this), then traditional approach does not take these baselines into account -->
<!-- - problem with robust approach is that is does not take into account the effect of a NoGo-trials -->
<!-- We will determine PES -->

<!-- **cant really get a number ms-slowing, only the effect of errors on their trial** -->

<!-- The classic approad represents main effect of in  -->
<!-- The robust effect represents main effect od in -->
<!-- But I want: -->
<!-- So I am using interaction term -->
<!-- Whenever the findings differ in either the classical or robust approach I will mention this -->
<!-- Can find all analysis done with classical/robust approaches in appendix -->


<!-- PES was defined using the traditional approach^[We conducted all behavioral and DDM analysis with the robust measure of PES [@dutilh2012how]. Results did not differ significantly, see Appendix //REPLACE// for Detail] [@dutilh2012how; @pfister2022]. Mean response times $\overline{RT}$ in Go trials following a false response to a NoGo trial ($E+1$) are compared to mean response times following a correct response to a NoGo trial ($C+1$).  -->
<!-- $$\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$$ -->

<!-- Effects of RSI condition and accuracy of the previous NoGo trial as well as their interaction on mean response times and accuracy are examined using a two-way ($RSI \times previous \ accuracy$) repeated measures ANOVA. -->

## Bayesian drift-diffusion model
The diffusion model was estimated using a Bayesian approach implemented in the R-package `brms` [@R-brms_a]. Bayesian estimation produces more accurate parameter estimates [@rouder2005]. A further benefit is its ability to fully infer posterior distributions and thus allow a more intuitive quantification of uncertainty [@kruschke2010].

## Model comparison
To examine the best-fitting model able to explain post-error effects we restricted the full location dataset to only include pre-error (E-1) and post-error (E+1) trials in both RSI conditions. We then selectively disabled the impact of RSI or _error-condition_ on parameters and estimated their pointwise out-of-sample prediction accuracy using the PSIS-LOO criterion [@vehtari2017] approximation  implemented in the `loo` package [@R-loo_b].

A model with the factors RSI and error-condition both affecting all parameters was used as a baseline. We tested 14 other models that selectively disabled the impact of one of the factors on either all, one or all but one parameters of the model. This results in 1 baseline model, 1 model with RSI not impacting any parameters, 1 model with error-condition not affecting any parameter, 4 models with only one of the 4 DDM parameters varying between error-conditions, 4 models with one of the parameters not being allowed to vary between error-conditions and 4 models with one of the parameters not being allowed to vary between RSI conditions. The parameter specification of the best fitting model was then employed on the full location dataset and is reported below.

## Model specification
<!-- A full description of model specification will be found in [Appendix B](##model-specification). -->
<!-- To allow for an in-depth overview of the effect of errors on cognitive processes we not only looked at post-correct trials (C+1) and post-error trials (E+1) but extended our model to include pre-error (E-1), pre-correct (C-1) and trials 2 responses after a NoGo-trial (E+2 -- C+2). This model allows for comparisons drawn by traditional ($\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$) as well as robust ($\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{E-1}}$) definitions of PES. It furthermore allows for comparisons of trials preceding either an error or a correct-trial and investigating the duration of error-related effects by inspecting the change from trials immediately following the error to trials 2 responses after the error.  -->

Let $\mathbf{Y_{(ijk)}}$ represent a response vector of the decision and response time $(X_{(ijk)}, T_{(ijk)})$ for the $i$th participant, in the $j$th trial of the $k$th condition. The data is assumed to follow a Wiener distribution,
$$\mathbf{Y_{(ijk)}} \sim Wiener(\alpha_{(ijk)}, \beta_{(ijk)}, \tau_{(ijk)}, \delta_{(ijk)})$$
with the four model parameters boundary separation $\alpha$, bias $\beta$, non-decision time $\tau$ and drift-rate $\delta$. Responses $X_{(ijk)}$ can take the values $X_{(ijk)} = \{0,1\}$. $X_{(ijk)} = 0$ represents the decision that the stimulus shows the letter _X_, corresponding to the lower response boundary. $X_{(ijk)} = 1$ represents the respective decision that the stimulus shows the letter _Y_. Response time (in $s$) can take on any value $T_{(ijk)} \in (0, 0.8]$. A response $\mathbf{Y_{(ijk)}}$ of participant $i$ on trial $j$ is further influenced by the combination $k$ of the conditions RSI (short -- long) and location (C-1, E-1, E+1 ...).
**watch out for location here**

All parameters were allowed to vary between conditions (see Figure \@ref(fig:method-display-model-spec)). All intercepts were fixed to zero in order to estimate parameters for each combination of factors instead of deviations from a baseline, easing specification of priors [@singmann2017intro]. Since only differences between conditions were of interest in this study and because the model had convergence issues when fitting it in a hierarchical manner, we chose to use the _complete pooling_ technique to estimate diffusion model parameters^[The hierarchical model produced slightly better fit and had acceptable $\hat{R}$ values, but ended with a large number of divergent transitions. Main effects reported here did not differ in the hierarchical model. See appendix //REPLACE// for further details].
<!-- **and estimating uncertainty for each combination of factors, instead of main effect -- thanks valentin //Citation here**  -->
Drift rate was further allowed to vary depending on the true status of the presented stimulus $s$, accounting for differences in drift direction depending on the presented stimulus. Because the task relied heavily on the alternation of stimuli "X" and "Y", the bias parameter was allowed to vary depending on the status of the previously presented stimulus $p$.
<!-- The model estimates parameters defining the group-level distribution from which individual-level parameters are then drawn. Boundary separation $\alpha_{ik}$ of individual $i$ in condition $k$, for example, is assumed to follow the distribution $\alpha_{ik} \sim N(\mu_{\alpha k}, \sigma_{\alpha k})$.  -->

(ref:method-display-model-spec-caption) Graphical representation of model specification. Shaded nodes represent measured parameters. 

```{r method-display-model-spec, fig.cap = paste("(ref:method-display-model-spec-caption)")}
knitr::include_graphics(
  "images/model_spec_slide_image.jpg"
)
```


Priors for the parameters were specified in a weakly informative manner. Priors were specified simultaneously for all conditions $k$ of a diffusion model parameter. The index $k$ is thus omitted.

$$\delta \sim Normal(0, 5)$$
<!-- $$\sigma_{\delta} \sim Gamma(2, 0.3)$$ -->
$$\alpha \sim Gamma(10, 5)$$
<!-- $$\sigma_{\alpha} \sim Normal^{+}(0, 0.3)$$ -->
$$\tau \sim Gamma(1, 5)$$
<!-- $$\sigma_{\tau} \sim Normal^{+}(0, 0.3)$$ -->
$$\tau \sim Beta(4, 4)$$
<!-- $$\sigma_{\beta} \sim Normal^{+}(0, 0.3)$$ -->
<!-- Bias $\beta$ was set to 0.5 for all participants and trials, as there was no reason to assume any a-priori bias towards one response alternative ("X" - "Y") ^[This assumption was confirmed by exploratory analysis with the bias parameter being allowed to vary freely between participants and response-mapping instructions. The bias parameter was estimated at 0.5 by the model for both mapping conditions. Consult Appendix REPLACE for further details]. None of the parameters were transformed before analysis, easing prior specification and model interpretation [@singmann2017intro]. **provide proof for bias estimation (Appendix)**  -->
<!-- **random effects correlations prior** -->
```{r method-spec-table, echo = FALSE, warning=FALSE, eval = FALSE}
prior_table <- data.table(
  `Group-Level Parameter` = c("$\\mu_{\\delta}$", "$\\sigma_{\\delta}$", "$\\mu_{\\alpha}$", "$\\sigma_{\\alpha}$", "$\\mu_{\\tau}$", "$\\sigma_{\\tau}$", "$\\mu_{\\beta}$", "$\\sigma_{\\beta}}$"),
  Prior = c(
    "$\\mu_{\\delta} \\sim Cauchy(0, 5)$", "$\\sigma_{\\delta} \\sim Normal^{+}(0, 0.3)$",  "$\\mu_{\\alpha} \\sim Normal^{+}(1.5, 1)$", "$\\sigma_{\\alpha} \\sim Normal^{+}(0, 0.3)$", "$\\mu_{\\tau} \\sim Normal^{+}(0.15, 0.1)$", "$\\sigma_{\\tau} \\sim Normal^{+}(0, 0.3)$",
    "$\\mu_{\\beta} \\sim Normal^{+}(0.5, 0.25)$", "$\\sigma_{\\beta} \\sim Normal^{+}(0, 0.3)$"
  )
)
# maybe put estimation formula in here?
apa_table(prior_table, caption = "Specification of diffusion model parameters", note = "The index k denoting condition is dropped, as all conditions received equal priors. Boundary separation, non-decision time and group-level standard deviation priors received a lower bound of 0.", escape = FALSE)
```
<!-- Let $\mathbf{Y_{(ij)}}$ denote a response vector of the decision and response time $(X_{(ij)}, T_{(ij)})$ for the _p_ th participant, in the _j_ th trial in  condition _c_ (0,1) with previous accuracy _a_ (0,1). The data is assumed to follow a Wiener distribution, -->
<!-- $$\mathbf{Y_{(ij)}} \sim Wiener(\alpha_{(ij)}, \beta_{(ij)}, \tau_{(ij)}, \delta_{(ij)})$$ -->
<!-- with the four model parameters boundary separation $\alpha$, bias $\beta$, non-decision time $\tau$ and drift-rate $\delta$.  -->
<!-- The index notation suggests that drift rates can differ across participants ($i$) as well as across trials ($j$). This model was constrained by treating all trials for the same participant with the equal previous accuracy **in the same RSI? ** as identical. At the participant level, three parameters $\alpha$, $\tau$ and $\delta$ were allowed to vary between participants, with $\beta$ being fixed to 0.5. This was done to reduce model complexity, as there is no reason to assume a bias towards any decision. **maybe have it depend on map condition, or do a prior test here?** -->
<!-- Influence of RSI condition as well as accuracy of the previous trial was investigated for the parameters $\alpha$, $\tau$ and $\delta$ via regression of the parameters on the factors _RSI_ and _previous accuracy_. Random slopes for the factor RSI were included to allow for interindividual differences in mean parameter values and the effect of RSI. **really random intercepts, why not random slopes prev_acc, model test?** -->
<!-- Formulas -->
<!-- $$\delta_{ij} = \theta_{RSI(i)} + \beta_{2}A{j} + \beta_{3}A_jC_j + $$ -->
<!-- maybe use this: equatiomatic::extract_eq(lme4::lmer(rt ~ 0 + rsi*error_factor + (0 + rsi|id), data = data_classic)) -->
<!-- $$\delta_{(ij)} = \nu_{(i)} + \epsilon_{(ij)}$$ -->
<!-- $$\epsilon_{(ij)} \sim N(0, \eta^2_{\epsilon})$$ -->
<!-- $$\nu_{(p)} \sim N(\mu_{\nu}, \sigma^2_{\nu})$$ -->

```{r method-setup-model}
n_iter <- 3000
n_warmup <- 1000
n_chains <- 4
n_cores <- 64
max_depth <- 15
adapt_delta <- 0.95
seed <- 1234

model_setup_values <- data.frame(n_iter, n_warmup, n_chains, n_cores, max_depth,
                                 adapt_delta, seed)
```

## Model analysis
**We run model comparisons in robust models, and full model in the full location model**
The diffusion model runs `r model_setup_values$n_chains` chains for `r model_setup_values$n_iter` iterations each, with `r model_setup_values$n_warmup` iterations per chain being used as a warmup to adapt the sampler. Final analysis was based on `r (model_setup_values$n_iter - model_setup_values$n_warmup)*model_setup_values$n_chains` iterations. Treedepth was set to `r model_setup_values$max_depth` and `adapt_delta` was set to `r model_setup_values$adapt_delta`. Following checks for model convergence, we will draw posterior samples and asses the fit of the model to our experimental data. We will compare parameter posterior distributions between levels of the conditions $k$ to investigate the effects of errors and RSI on diffusion model parameters. A full model using the _location_ approach will grant an overview over the development of parameters following error responses. Post-error effects will be quantified by comparing parameters in locations pre-error (E-1) to post-error (E+1).
