# Method
```{r method-source-data-prep, child = "./markdown/data_prep.rmd"}
```

## Participants
```{r method-source-power-analysis, child = "./markdown/power_analysis.rmd"}
```
We conducted a power analysis using the the R package `superpower` [@R-Superpower] with values based on previous studies [@dutilh2012testing; @dutilh2013] to determine the minimum sample size needed to detect an interaction effect of RSI (short -- long) and _previous accuracy_ (post-correct -- post-error) on drift rate and boundary separation. Mean values and standard deviations for each cell were entered into the model to estimate effect sizes, returning interaction effects of partial $\eta^2 =$ `r partial_eta_interaction_drift` and `r partial_eta_interaction_boundary` for effects on drift rate and boundary separation, respectively. Using bonferroni corrected significance criteria of $\alpha$ = `r alpha_level_power` and power $= .80$, the minimum sample size required to detect the hypothesized interaction effects was estimated to be N = `r required_n_boundary` for effects on boundary separation and N = `r required_n_drift` for effects on drift rate. Exact values entered into analysis can be found in Table \@ref(tab:appendix-mean-values-power-analysis) in the appendix. We recruited a total of `r demo_output$n_subjects` (`r demo_output$n_women` females, M = `r round(demo_output$mean_age, 2)`, SD = `r round(demo_output$sd_age, 2)`) participants to ensure adequate power even after potential drop out. Participants were tested in a single session, gave informed consent and received course credit for their participation.

## Materials
The experiment was programmed using the PsychoPy software [@peirce2019]. We used a modified version of the Behavior Adaptation Task (BAT) [@hester2007] -- a motor-inhibition Go-NoGo task. Stimuli consisted of a stream of the letters X and Y presented in black centrally on a grey background (see Figure \@ref(fig:method-bat-example)). Subjects were asked to respond to the letters when they occurred in an alternating pattern (Go trial) but withhold their response on repeated presentation of a stimulus (NoGo trial). Letters measured approximately 2.5 degrees vertically, the fixation cross measured 1 degree horizontally and vertically and was printed black. 

(ref:method-bat-example-caption) Behavioral Adaptation Task

```{r method-bat-example, fig.cap = paste("(ref:method-bat-example-caption)")}
knitr::include_graphics(
  "images/bat_slide_pp/Slide1.png"
)
```

<!-- ![Behavior Adaptation Task](images/bat_slide_pp/Slide1.png) -->


## Procedure
Participants were asked to respond as quickly and accurately as possible. Instructions on response mappings of stimuli X and Y to the response keys D and L were counterbalanced across participants. Stimuli were presented for 800ms or until a response was given. We set the RSI to 200ms for the short condition and 1000ms for the long condition. A fixation cross was presented during the RSI. Participants completed 30 practice trials, 15 of which with short RSI and 15 with long RSI. Participants received feedback informing them about their performance only in practice trials. **The word "richtig" (german for _correct_) was printed in green following a correct response, "falsch" was printed in red following a false response. When participants erroneously responded in a NoGo-trial, participants were reminded not to respond when stimuli were repeated.** RSI was manipulated between experimental blocks, with six blocks consisting of 250 trials each being presented per RSI condition. Blocks of short and long RSI occurred in an alternating pattern, beginning with the long RSI condition. A self-paced break was administered following each experimental block. **instruction screens (german) can be found in supplementary materials?)** The sequence of appearance of stimuli X and Y was generated pseudo-randomly. Fourfold repetitions of a stimulus were prohibited, and NoGo-trials were always preceeded by another NoGo trial or at least two Go trials. This was done to ensure that post-error trials were never simultaneously pre-error trials. 

## Data preparation
All response times shorter than 150ms were excluded from analysis. Mean RT and accuracy for each participant in each combination of RSI (short -- long) and trial type (Go -- NoGo) were considered outliers if the participant's mean deviated more than 3 standard deviations from the mean across participants for that combination of RSI and trial type. A total of `r n_outliers` participants were excluded due to this criterion, leaving `r demo_output$n_subjects - n_outliers` participants for analysis.

<!-- Exclude first 10 trials in each first occurence of RSI block -->
<!-- Within-participant logarithmized response times deviating more than 3 standard deviations from the participants' condition-specific mean were also considered outliers. Of the `r nrow(rt_data)` trials `r paste(formattable::percent((n_outliers*3000) / nrow(final_data)))` of trials were lost due to participant exclusion, `r demo_output$percentage_trials_lost`% of trials were lost due to single trial outliers, leaving `r nrow(final_data)` trials for analysis. -->

## Behavioral Analysis
A key 
Only errors in NoGo trials were considered _error trials_ relevant for analysis. PES was defined using the traditional approach^[We conducted all behavioral and DDM analysis with the robust measure of PES [@dutilh2012how]. Results did not differ significantly, see Appendix //REPLACE// for Detail] [@dutilh2012how; @pfister2022]. Mean response times $\overline{RT}$ in Go trials following a false response to a NoGo trial ($E+1$) are compared to mean response times following a correct response to a NoGo trial ($C+1$). 
$$\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$$
Effects of RSI condition and accuracy of the previous NoGo trial as well as their interaction on mean response times and accuracy were then examined using a two-way ($RSI \times previous \ accuracy$) repeated measures ANOVA.

## Bayesian hierarchical drift-diffusion model
The diffusion model was estimated using a Bayesian hierarchical approach implemented in the R-package `brms` [@R-brms_a]. Hierarchical approaches to the DDM allow simultaneous estimation of parameters on both a population-level and on a subject-level [@vandekerckhove2011; @lee2011; @gelman2006], reducing the number of samples required to estimate model parameters reliably [@wiecki2013; @ratcliff2015; @rouder2005]. Bayesian estimation allows hierarchical extensions of the model otherwise not feasible in frequentist approaches using maximum likelihood estimation [@vandekerckhove2011] and produces more accurate model estimates [@rouder2005]. Individual-level parameters are assumed to be random samples drawn from a group-level distribution. Group-level distributions thus define between-subjects variability of the parameters and are themselves specified by a set of parameters [@matzke2009]. The ability to fully infer posterior distributions and thus allow a more intuitive quantification of uncertainty is a further benefit of bayesian estimation [@kruschke2010].

## Model specification
<!-- A full description of model specification will be found in [Appendix B](##model-specification). -->
Let $\mathbf{Y_{(ij)}}$ represent a response vector of the decision and response time $(X_{(ij)}, T_{(ij)})$ for the $i$th participant, in the $j$th trial. The data is assumed to follow a Wiener distribution,
$$\mathbf{Y_{(ij)}} \sim Wiener(\alpha_{(ij)}, \beta_{(ij)}, \tau_{(ij)}, \delta_{(ij)})$$
with the four model parameters boundary separation $\alpha$, bias $\beta$, non-decision time $\tau$ and drift-rate $\delta$. Responses $X_{(ij)}$ can take the values $X_{(ij)} = \{0,1\}$. $X_{(ij)} = 0$ represents the decision that the stimulus shows the letter _X_, corresponding to the lower response boundary. $X_{(ij)} = 1$ represents the respective decision that the stimulus shows the letter _Y_. Response time (in $s$) can take on any value $T_{(ij)} \in (0, 0.8]$. A response $\mathbf{Y_{(ij)}}$ of participant $i$ on trial $j$ is further influenced by the trial parameters $rsi_{(j)}$ (short -- long), previous accuracy $acc_{(j)}$(C+1 -- E+1) and stimulus type $stim_{(j)}$ ("X" -- "Y").

<!-- Sorry for the next sentence, Dirk -->
Because individual differences were not of interest in the present study and in an effort to reduce computation time, the parameters drift rate $\delta$, non-decision time $\tau$ and boundary separation $\alpha$ were constrained to be equal for all participants but allowed to vary between conditions. For these three parameters, the model estimated fixed effects of the factors RSI (short - long), accuracy of the previous NoGo-trial (C+1 - E+1) and their interaction. All intercepts were fixed to zero in order to estimate group-level parameters for each combination of factors instead of deviations from a baseline, easing specification of priors [@singmann2017intro]. **and estimating uncertainty for each combination of factors, instead of main effect -- thanks valentin //Citation here** Drift rate was further allowed to vary depending on the true status of the presented stimulus, accounting for differences in drift direction depending on the presented stimulus.
**add hddm-like description (graph) here and a section specifying model priors**
**add an index for conditon here-to show that these may vary between conditions**
**corr-matrix here, too?**

Priors for the regression weights of fixed effects were specified in a weakly informative manner (see Table \@ref(tab:method-spec-table)). Bias $\beta$ was set to 0.5 for all participants and trials, as there was no reason to assume any a-priori bias towards one response alternative ("X" - "Y") ^[This assumption was confirmed by exploratory analysis with the bias parameter being allowed to vary freely between participants and response-mapping instructions. The bias parameter was estimated at 0.5 by the model for both mapping conditions. Consult Appendix REPLACE for further details]. None of the parameters were transformed before analysis, easing prior specification and model interpretation [@singmann2017intro]. **provide proof for bias estimation (Appendix)** 
```{r method-spec-table, echo = FALSE, warning=FALSE}
prior_table <- data.table(
  Parameter = c("Drift Rate", "Boundary Separation", "Non-decision Time"),
  Formula = c(
    "$\\delta \\sim 0 + rsi:acc:stim$",
    "$\\alpha \\sim 0 + rsi:acc$",
    "$\\tau \\sim 0 + rsi:acc$"
  ),
  Prior = c(
    "$\\delta \\sim Cauchy(0, 5)$", "$\\alpha \\sim Normal^{+}(1.5, 1)$", "$\\tau \\sim Normal^{+}(0.15, 0.1)$"
  )
)
# maybe put estimation formula in here?
apa_table(prior_table, caption = "Specification of diffusion model parameters", note = "Boundary separation and non-decision priors received a lower bound of 0. Formula represents model syntax used for specification in brms. $acc$ represents the accuracy of the previous trial. $stim$ represents the stimulus of the current trial", escape = FALSE)
```
<!-- Let $\mathbf{Y_{(ij)}}$ denote a response vector of the decision and response time $(X_{(ij)}, T_{(ij)})$ for the _p_ th participant, in the _j_ th trial in  condition _c_ (0,1) with previous accuracy _a_ (0,1). The data is assumed to follow a Wiener distribution, -->
<!-- $$\mathbf{Y_{(ij)}} \sim Wiener(\alpha_{(ij)}, \beta_{(ij)}, \tau_{(ij)}, \delta_{(ij)})$$ -->
<!-- with the four model parameters boundary separation $\alpha$, bias $\beta$, non-decision time $\tau$ and drift-rate $\delta$.  -->
<!-- The index notation suggests that drift rates can differ across participants ($i$) as well as across trials ($j$). This model was constrained by treating all trials for the same participant with the equal previous accuracy **in the same RSI? ** as identical. At the participant level, three parameters $\alpha$, $\tau$ and $\delta$ were allowed to vary between participants, with $\beta$ being fixed to 0.5. This was done to reduce model complexity, as there is no reason to assume a bias towards any decision. **maybe have it depend on map condition, or do a prior test here?** -->
<!-- Influence of RSI condition as well as accuracy of the previous trial was investigated for the parameters $\alpha$, $\tau$ and $\delta$ via regression of the parameters on the factors _RSI_ and _previous accuracy_. Random slopes for the factor RSI were included to allow for interindividual differences in mean parameter values and the effect of RSI. **really random intercepts, why not random slopes prev_acc, model test?** -->
<!-- Formulas -->
<!-- $$\delta_{ij} = \theta_{RSI(i)} + \beta_{2}A{j} + \beta_{3}A_jC_j + $$ -->
<!-- maybe use this: equatiomatic::extract_eq(lme4::lmer(rt ~ 0 + rsi*error_factor + (0 + rsi|id), data = data_classic)) -->
<!-- $$\delta_{(ij)} = \nu_{(i)} + \epsilon_{(ij)}$$ -->
<!-- $$\epsilon_{(ij)} \sim N(0, \eta^2_{\epsilon})$$ -->
<!-- $$\nu_{(p)} \sim N(\mu_{\nu}, \sigma^2_{\nu})$$ -->

```{r method-setup-model}
n_iter <- 4000
n_warmup <- 2000
n_chains <- 4
n_cores <- 4
max_depth <- 15
adapt_delta <- 0.95
seed <- 1234

model_setup_values <- data.frame(n_iter, n_warmup, n_chains, n_cores, max_depth,
                                 adapt_delta, seed)
```

## Model analysis
The diffusion model runs `r model_setup_values$n_chains` chains for `r model_setup_values$n_iter` iterations each, with `r model_setup_values$n_warmup` iterations per chain being used as a warmup to adapt the sampler. Final analysis was based on `r (model_setup_values$n_iter - model_setup_values$n_warmup)*model_setup_values$n_chains` iterations. Treedepth was set to `r model_setup_values$max_depth` and `adapt_delta` was set to `r model_setup_values$adapt_delta`. Following checks for model convergence, we will draw posterior samples and asses the fit of the model to our experimental data. Fixed effects of RSI, previous accuracy and their interaction will be tested for significance via inspection their 95% credible interval.
