# Method
<!-- Notes: -->
<!-- conduct sensitivity anaylsis later? -->
<!-- Lakens 2020, sample size justification read! -->
<!-- Add the "later studies" when comparing results of sensitivity analysis -->
<!-- proportion of Nogo trials? -->

<!-- omega squared better effect size,  -->
<!-- bonferroni correction rausnehmen: Schulz, Grimes 2005 -->
<!-- Subjects in text == Participants -->

<!-- Distance to monitor  -->
<!-- Warum individuell keine ausreißer rausnehmen? Response window! -->
<!-- Abkürzungen 1x pro abschnitt? -->
<!-- Kurz was zur Verteilung der Normalverteilungen der RT sagen -->
```{r method-source-data-prep, child = "./markdown/data_prep.rmd"}
```

## Participants
```{r method-source-power-analysis, child = "./markdown/power_analysis.rmd", eval = TRUE}
```

```{r method-power-commented-out, eval = FALSE}
# <-- We conducted a power analysis using the the R package `superpower` [@R-Superpower] with values based on previous studies [@dutilh2012testing; @dutilh2013] to determine the minimum sample size needed to detect an interaction effect of RSI (short -- long) and _previous accuracy_ (post-correct -- post-error) on drift rate and boundary separation. Mean values and standard deviations for each cell were entered into the model to estimate effect sizes, returning interaction effects of partial $\eta^2 =$ `r partial_eta_interaction_drift` and `r partial_eta_interaction_boundary` for effects on drift rate and boundary separation, respectively. Using bonferroni corrected significance criteria of $\alpha$ = `r alpha_level_power` and power $= .80$, the minimum sample size required to detect the hypothesized interaction effects was estimated to be N = `r required_n_boundary` for effects on boundary separation and N = `r required_n_drift` for effects on drift rate. Exact values entered into analysis can be found in Table \@ref(tab:appendix-mean-values-power-analysis) in the appendix. -->
```
We recruited a total of `r demo_output$n_subjects` (`r demo_output$n_women` females, M = `r round(demo_output$mean_age, 2)`, SD = `r round(demo_output$sd_age, 2)`) participants. Participants were tested in a single session, gave informed consent and received course credit for their participation.

## Materials
The experiment was programmed using the PsychoPy software [@peirce2019]. We used a modified version of the Behavior Adaptation Task (BAT) [@hester2007] -- a motor-inhibition Go-NoGo task. Stimuli consisted of a stream of the letters X and Y presented in black centrally on a grey background (see Figure \@ref(fig:method-bat-example)). Participants were asked to respond to the letters when they occurred in an alternating pattern (Go trial) but withhold their response on repeated presentation of a stimulus (NoGo trial). Letters measured approximately 2.5 degrees vertically, the fixation cross measured 1 degree horizontally and vertically and was printed black. Participants were seated approximately 60cm away from the monitor.

(ref:method-bat-example-caption) Behavioral Adaptation Task

```{r method-bat-example, fig.cap = paste("(ref:method-bat-example-caption)")}
knitr::include_graphics(
  "images/bat_slide_pp/Slide1.png"
)
```

<!-- ![Behavior Adaptation Task](images/bat_slide_pp/Slide1.png) -->


## Procedure
Participants were asked to respond as quickly and accurately as possible. Instructions on response mappings of stimuli X and Y to the response keys D and L were counterbalanced across participants. Stimuli were presented for 800ms or until a response was given. We set the RSI to 200ms for the short condition and 1000ms for the long condition. A fixation cross was presented during the RSI. Participants completed 30 practice trials, 15 of which with short RSI and 15 with long RSI. Participants received feedback informing them about their performance only in practice trials. The word "richtig" (german for _correct_) was printed in green following a correct response, "falsch" (german for _incorrect_) was printed in red following a false response. When participants erroneously responded in a NoGo-trial, they were reminded not to respond when stimuli were repeated. RSI was manipulated between experimental blocks, with six blocks consisting of 250 trials each being presented per RSI condition. Blocks of short and long RSI occurred in an alternating pattern, beginning with the long RSI condition. A self-paced break was administered following each experimental block. **instruction screens (german) can be found in supplementary materials?)** The sequence of appearance of stimuli X and Y was generated pseudo-randomly. Fourfold repetitions of a stimulus were prohibited, and NoGo-trials were always preceded by another NoGo trial or at least two Go trials. This was done to ensure that post-error trials were never simultaneously pre-error trials. 

## Data preparation
All response times shorter than 150ms were excluded from analysis. Mean RT and accuracy for each participant in each combination of RSI (short -- long) and trial type (Go -- NoGo) were considered outliers if the participant's mean deviated more than 3 standard deviations from the mean across participants for that combination of RSI and trial type. A total of `r n_outliers` participants were excluded due to this criterion, leaving `r demo_output$n_subjects - n_outliers` participants for analysis. Since response times had an upper limit of 800ms, we chose not to exclude trial on a within-participant basis.

<!-- Exclude first 10 trials in each first occurence of RSI block -->
<!-- Within-participant logarithmized response times deviating more than 3 standard deviations from the participants' condition-specific mean were also considered outliers. Of the `r nrow(rt_data)` trials `r paste(formattable::percent((n_outliers*3000) / nrow(final_data)))` of trials were lost due to participant exclusion, `r demo_output$percentage_trials_lost`% of trials were lost due to single trial outliers, leaving `r nrow(final_data)` trials for analysis. -->

## Behavioral Analysis
Only errors in NoGo trials were considered _error trials_ relevant for analysis. Inspection of only the effect of accuracy in NoGo trials allows classification of Go trials based on the accuracy of the most proximate NoGo trial. Go trials following a NoGo-error are defined as trials _E+1_, Go trials following a correct response to a NoGo-trial as _C+1_. We also added the locations _E-1_, _C-1_, _E+2_ and _C+2_ depending on the distance and accuracy of the most proximate NoGo trial. This location-approach allows for the classification of PES as done by traditional methods, $$\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$$ 
as well as the robust approach to PES [@dutilh2012how].
$$ \Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{E-1}}$$
We will conduct main analyses using the classical definition of PES^[We conducted all behavioral and DDM analysis with the robust measure of PES [@dutilh2012how]. Results did not differ significantly, see Appendix //REPLACE// for Detail] to avoid potential overestimation of PES caused by _pre-error speeding_ [@pfister2022].
<!-- PES was defined using the traditional approach^[We conducted all behavioral and DDM analysis with the robust measure of PES [@dutilh2012how]. Results did not differ significantly, see Appendix //REPLACE// for Detail] [@dutilh2012how; @pfister2022]. Mean response times $\overline{RT}$ in Go trials following a false response to a NoGo trial ($E+1$) are compared to mean response times following a correct response to a NoGo trial ($C+1$).  -->
<!-- $$\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$$ -->
Effects of RSI condition and accuracy of the previous NoGo trial as well as their interaction on mean response times and accuracy are examined using a two-way ($RSI \times previous \ accuracy$) repeated measures ANOVA.

## Bayesian hierarchical drift-diffusion model
The diffusion model was estimated using a Bayesian hierarchical approach implemented in the R-package `brms` [@R-brms_a]. Hierarchical approaches to the DDM allow simultaneous estimation of parameters on both a population-level and on a subject-level [@vandekerckhove2011; @lee2011; @gelman2006], reducing the number of samples required to estimate model parameters reliably [@wiecki2013; @ratcliff2015; @rouder2005]. Bayesian estimation allows hierarchical extensions of the model otherwise not feasible in frequentist approaches using maximum likelihood estimation [@vandekerckhove2011] and produces more accurate model estimates [@rouder2005]. Individual-level parameters are assumed to be random samples drawn from a group-level distribution. Group-level distributions thus define between-subjects variability of the parameters and are themselves specified by a set of parameters [@matzke2009]. The ability to fully infer posterior distributions and thus allow a more intuitive quantification of uncertainty is a further benefit of bayesian estimation [@kruschke2010].

## Model specification
<!-- A full description of model specification will be found in [Appendix B](##model-specification). -->
<!-- To allow for an in-depth overview of the effect of errors on cognitive processes we not only looked at post-correct trials (C+1) and post-error trials (E+1) but extended our model to include pre-error (E-1), pre-correct (C-1) and trials 2 responses after a NoGo-trial (E+2 -- C+2). This model allows for comparisons drawn by traditional ($\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{C+1}}$) as well as robust ($\Delta_{PES} = \overline{RT_{E+1}} - \overline{RT_{E-1}}$) definitions of PES. It furthermore allows for comparisons of trials preceding either an error or a correct-trial and investigating the duration of error-related effects by inspecting the change from trials immediately following the error to trials 2 responses after the error.  -->

Let $\mathbf{Y_{(ijk)}}$ represent a response vector of the decision and response time $(X_{(ijk)}, T_{(ijk)})$ for the $i$th participant, in the $j$th trial of the $k$th condition. The data is assumed to follow a Wiener distribution,
$$\mathbf{Y_{(ijk)}} \sim Wiener(\alpha_{(ijk)}, \beta_{(ijk)}, \tau_{(ijk)}, \delta_{(ijk)})$$
with the four model parameters boundary separation $\alpha$, bias $\beta$, non-decision time $\tau$ and drift-rate $\delta$. Responses $X_{(ijk)}$ can take the values $X_{(ijk)} = \{0,1\}$. $X_{(ijk)} = 0$ represents the decision that the stimulus shows the letter _X_, corresponding to the lower response boundary. $X_{(ijk)} = 1$ represents the respective decision that the stimulus shows the letter _Y_. Response time (in $s$) can take on any value $T_{(ijk)} \in (0, 0.8]$. A response $\mathbf{Y_{(ijk)}}$ of participant $i$ on trial $j$ is further influenced by the combination $k$ of the conditions RSI (short -- long) and location (C-1, E-1, E+1 ...).
**watch out for location here**

<!-- Sorry for the next sentence, Dirk -->
The parameters drift rate $\delta$, non-decision time $\tau$ and boundary separation $\alpha$ were allowed to vary between conditions (see Figure \@ref(fig:method-display-model-spec)). All intercepts were fixed to zero in order to estimate group-level parameters for each combination of factors instead of deviations from a baseline, easing specification of priors [@singmann2017intro]. **and estimating uncertainty for each combination of factors, instead of main effect -- thanks valentin //Citation here** Drift rate was further allowed to vary depending on the true status of the presented stimulus, accounting for differences in drift direction depending on the presented stimulus.
The model estimates parameters defining the group-level distribution from which individual-level parameters are then drawn. Drift rates $\delta_{ik}$ of individual $i$ in condition $k$, for example, are assumed to follow the distribution $\delta_{ik} \sim N(\mu_{\delta k}, \sigma_{\delta k})$. 

(ref:method-display-model-spec-caption) Graphical representation of model specification. Shaded nodes represent measured parameters, all other parameters are estimated by the model.

```{r method-display-model-spec, fig.cap = paste("(ref:method-display-model-spec-caption)")}
knitr::include_graphics(
  "images/model_spec_slide_image.jpg"
)
```


Priors for the group-level parameters were specified in a weakly informative manner.

$$\mu_{\delta} \sim Normal(0, 5)$$
$$\sigma_{\delta} \sim Normal^{+}(0, 0.3)$$
$$\mu_{\alpha} \sim Normal^{+}(1.5, 1)$$
$$\sigma_{\alpha} \sim Normal^{+}(0, 0.3)$$
$$\mu_{\tau} \sim Normal^{+}(0.15, 0.1)$$
$$\sigma_{\tau} \sim Normal^{+}(0, 0.3)$$


Bias $\beta$ was set to 0.5 for all participants and trials, as there was no reason to assume any a-priori bias towards one response alternative ("X" - "Y") ^[This assumption was confirmed by exploratory analysis with the bias parameter being allowed to vary freely between participants and response-mapping instructions. The bias parameter was estimated at 0.5 by the model for both mapping conditions. Consult Appendix REPLACE for further details]. None of the parameters were transformed before analysis, easing prior specification and model interpretation [@singmann2017intro]. **provide proof for bias estimation (Appendix)** 
**random effects correlations prior**
```{r method-spec-table, echo = FALSE, warning=FALSE, eval = FALSE}
prior_table <- data.table(
  `Group-Level Parameter` = c("$\\mu_{\\delta}$", "$\\sigma_{\\delta}$", "$\\mu_{\\alpha}$", "$\\sigma_{\\alpha}$", "$\\mu_{\\tau}$", "$\\sigma_{\\tau}$"),
  Prior = c(
    "$\\mu_{\\delta} \\sim Cauchy(0, 5)$", "$\\sigma_{\\delta} \\sim Normal^{+}(0, 0.3)$",  "$\\mu_{\\alpha} \\sim Normal^{+}(1.5, 1)$", "$\\sigma_{\\alpha} \\sim Normal^{+}(0, 0.3)$", "$\\mu_{\\tau} \\sim Normal^{+}(0.15, 0.1)$", "$\\sigma_{\\tau} \\sim Normal^{+}(0, 0.3)$"
  )
)
# maybe put estimation formula in here?
apa_table(prior_table, caption = "Specification of diffusion model parameters", note = "The index k denoting condition is dropped, as all conditions received equal priors. Boundary separation, non-decision time and group-level standard deviation priors received a lower bound of 0.", escape = FALSE)
```
<!-- Let $\mathbf{Y_{(ij)}}$ denote a response vector of the decision and response time $(X_{(ij)}, T_{(ij)})$ for the _p_ th participant, in the _j_ th trial in  condition _c_ (0,1) with previous accuracy _a_ (0,1). The data is assumed to follow a Wiener distribution, -->
<!-- $$\mathbf{Y_{(ij)}} \sim Wiener(\alpha_{(ij)}, \beta_{(ij)}, \tau_{(ij)}, \delta_{(ij)})$$ -->
<!-- with the four model parameters boundary separation $\alpha$, bias $\beta$, non-decision time $\tau$ and drift-rate $\delta$.  -->
<!-- The index notation suggests that drift rates can differ across participants ($i$) as well as across trials ($j$). This model was constrained by treating all trials for the same participant with the equal previous accuracy **in the same RSI? ** as identical. At the participant level, three parameters $\alpha$, $\tau$ and $\delta$ were allowed to vary between participants, with $\beta$ being fixed to 0.5. This was done to reduce model complexity, as there is no reason to assume a bias towards any decision. **maybe have it depend on map condition, or do a prior test here?** -->
<!-- Influence of RSI condition as well as accuracy of the previous trial was investigated for the parameters $\alpha$, $\tau$ and $\delta$ via regression of the parameters on the factors _RSI_ and _previous accuracy_. Random slopes for the factor RSI were included to allow for interindividual differences in mean parameter values and the effect of RSI. **really random intercepts, why not random slopes prev_acc, model test?** -->
<!-- Formulas -->
<!-- $$\delta_{ij} = \theta_{RSI(i)} + \beta_{2}A{j} + \beta_{3}A_jC_j + $$ -->
<!-- maybe use this: equatiomatic::extract_eq(lme4::lmer(rt ~ 0 + rsi*error_factor + (0 + rsi|id), data = data_classic)) -->
<!-- $$\delta_{(ij)} = \nu_{(i)} + \epsilon_{(ij)}$$ -->
<!-- $$\epsilon_{(ij)} \sim N(0, \eta^2_{\epsilon})$$ -->
<!-- $$\nu_{(p)} \sim N(\mu_{\nu}, \sigma^2_{\nu})$$ -->

```{r method-setup-model}
n_iter <- 4000
n_warmup <- 2000
n_chains <- 4
n_cores <- 4
max_depth <- 15
adapt_delta <- 0.95
seed <- 1234

model_setup_values <- data.frame(n_iter, n_warmup, n_chains, n_cores, max_depth,
                                 adapt_delta, seed)
```

## Model analysis
The diffusion model runs `r model_setup_values$n_chains` chains for `r model_setup_values$n_iter` iterations each, with `r model_setup_values$n_warmup` iterations per chain being used as a warmup to adapt the sampler. Final analysis was based on `r (model_setup_values$n_iter - model_setup_values$n_warmup)*model_setup_values$n_chains` iterations. Treedepth was set to `r model_setup_values$max_depth` and `adapt_delta` was set to `r model_setup_values$adapt_delta`. Following checks for model convergence, we will draw posterior samples and asses the fit of the model to our experimental data. We will compare group-level parameter posterior distributions between levels of the condition $k$ to investigate the effects of trial location (proximity to errors) and RSI.
